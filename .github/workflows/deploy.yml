name: Deploy Databricks (Terraform)

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - uses: actions/checkout@v4

      - name: Fail fast if secrets missing
        run: |
          if [ -z "$DATABRICKS_HOST" ]; then
            echo "DATABRICKS_HOST is empty. Add it in GitHub Secrets."
            exit 1
          fi
          if [ -z "$DATABRICKS_TOKEN" ]; then
            echo "DATABRICKS_TOKEN is empty. Add it in GitHub Secrets."
            exit 1
          fi
          echo "Using host: $DATABRICKS_HOST"

      - name: Install Databricks CLI (new)
        run: |
          # Official installer for the *new* Databricks CLI (provides `databricks` binary)
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
          databricks --version

      - name: Databricks CLI sanity
        run: |
          databricks --version
          databricks workspace --help

      - name: Check Databricks auth
        run: |
          databricks workspace list /

      - name: Sync workspace files (import notebook + monitoring)
        run: |
          # Use a folder that won't collide with an existing notebook
          WS_ROOT="/Users/olants@gmail.com/mlops-lab4-repo"

          databricks workspace mkdirs "$WS_ROOT"

          # Notebook import (single file) is fine with overwrite
          databricks workspace import "$WS_ROOT/mlops-lab4" \
            --overwrite \
            --format JUPYTER \
            --file "mlops-lab4.ipynb"

          # Import the whole monitoring folder (recommended)
          databricks workspace import-dir "monitoring" "$WS_ROOT/monitoring" --overwrite

          databricks workspace list "$WS_ROOT"
          databricks workspace list "$WS_ROOT/monitoring"
          echo "Workspace sync done: $WS_ROOT"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform init/apply (base infra)
        working-directory: terraform
        run: |
          terraform init
          terraform apply -auto-approve \
            -var="databricks_host=${DATABRICKS_HOST}" \
            -var="databricks_token=${DATABRICKS_TOKEN}" \
            -var="serving_token=${DATABRICKS_TOKEN}" \
            -var="train_notebook_path=/Users/olants@gmail.com/mlops-lab4-repo/mlops-lab4" \
            -var="drift_py_path=/Users/olants@gmail.com/mlops-lab4-repo/monitoring/drift_check.py" \
            -var="slo_py_path=/Users/olants@gmail.com/mlops-lab4-repo/monitoring/slo_probe.py" \
            -var="enable_serving=false"

      - name: Trigger training job (optional but useful)
        run: |
          # If you output train_job_id, trigger it.
          # If not, you can skip this step.
          if terraform -chdir=terraform output -raw train_job_id >/tmp/train_job_id 2>/dev/null; then
            JOB_ID=$(cat /tmp/train_job_id)
            echo "Triggering train job: $JOB_ID"
            databricks jobs run-now --job-id "$JOB_ID"
          else
            echo "No terraform output train_job_id found; skipping job trigger."
          fi

      - name: Update green to latest model version + re-apply Terraform
        env:
          MODEL_NAME: energy-lstm
        run: |
          python -m pip install --upgrade pip
          pip install databricks-sdk==0.44.0

          python - <<'PY'
          import os
          from databricks.sdk import WorkspaceClient

          w = WorkspaceClient(host=os.environ["DATABRICKS_HOST"], token=os.environ["DATABRICKS_TOKEN"])
          model = os.environ["MODEL_NAME"]

          versions = list(w.model_registry.list_model_versions(name=model))
          if not versions:
            raise SystemExit(f"No versions found for model {model}. Run training first.")

          latest = max(int(v.version) for v in versions)
          print("LATEST_VERSION", latest)

          tfvars_path = "terraform/terraform.tfvars"
          with open(tfvars_path, "w", encoding="utf-8") as f:
            f.write(f'green_model_version = "{latest}"\n')
            f.write('blue_traffic_percent = 100\n')
            f.write('green_traffic_percent = 0\n')
          PY

          terraform -chdir=terraform apply -auto-approve \
            -var="databricks_host=${DATABRICKS_HOST}" \
            -var="databricks_token=${DATABRICKS_TOKEN}" \
            -var="serving_token=${DATABRICKS_TOKEN}" \
            -var="train_notebook_path=/Users/olants@gmail.com/mlops-lab4-repo/mlops-lab4" \
            -var="drift_py_path=/Users/olants@gmail.com/mlops-lab4-repo/monitoring/drift_check.py" \
            -var="slo_py_path=/Users/olants@gmail.com/mlops-lab4-repo/monitoring/slo_probe.py" \
            -var="enable_serving=true"
